---
title: "Reducing Latency in Deepgram Live Streaming from Zoom"
description: "Techniques to mitigate latency when using Deepgram's live speech-to-text streaming with Zoom."
summary: "This article provides guidance on addressing latency issues that may arise when integrating Deepgram's live streaming transcription service with Zoom meetings. It covers optimising network bandwidth, configuring tools like Ngrok and Node Media Server, and enhancing the data pipeline."
---

<CommunityQuestion>I'm integrating Deepgram's live transcription with Zoom, but experiencing frustrating latency issues. Are there any techniques to reduce delays and improve real-time streaming performance?</CommunityQuestion>

When integrating Deepgram's live streaming transcription service with Zoom, you may occasionally experience latency issues. Addressing the following areas can help mitigate these delays:

#### Optimizing Network and Bandwidth
- **Check Bandwidth**: Ensure that both upload and download bandwidths fulfill the requirements for uninterrupted streaming. Network congestion or drops can introduce latency.
- **Prefer Wired Connections**: Opt for a wired internet connection over wireless to reduce packet loss and latency.

#### Reviewing Ngrok and Node Media Server Setup
- **Upgrade Ngrok**: Using ngrok's free version might introduce constraints. Consider upgraded options for potentially better performance or use alternatives like LocalTunnel or Serveo.
- **Node Media Server**: Ensure it's properly configured, and allocate ample memory and CPU resources. Verify CPU load during streaming, avoiding server overload.

#### Enhancing Python Processing Efficiency
- **Code Optimization**: Profile and optimize your Python code to ensure it's processing data swiftly.
- **Modular Testing**: Test the script independently to identify potential bottlenecks and address them.

#### Adjusting Zoom Settings
- **Optimize Video**: In Zoom settings, reduce video resolution or disable video enhancements, which can demand more bandwidth and increase latency.

#### Monitoring and Debugging
- **Utilize Logs**: Continuously monitor logs from ngrok, Node Media Server, and Python scripts to determine where latency is introduced.
- **Latency Timestamps**: Implement timestamps in these logs to track latency patterns across different stages of the pipeline.

#### Server and Resource Management
- **Cluster Resources**: Ensure your server is not overcommitting its processing capacity and that it's specifically tailored for real-time streaming requirements.

#### Consider Alternative Solutions
- Experiment with direct connections by temporarily removing ngrok or using a more performant tunneling service. 
- If early troubleshooting doesnâ€™t yield results, consult Deepgram support for more dedicated advice.

By thoroughly checking each component of your setup, you can significantly reduce latency and enhance live streaming performance.

#### References
- [Using Zoom & Deepgram](https://developers.deepgram.com/docs/integrate-deepgram-with-zoom)
- [Deepgram Streaming Documentation](https://developers.deepgram.com/docs/getting-started-with-live-streaming-audio)
- [Ngrok Documentation](https://ngrok.com/docs)
- [Node Media Server GitHub](https://github.com/illuspas/Node-Media-Server)
- [Python Code Optimization Tips](https://realpython.com/python-performance/)

#### Conclusion
These optimizations and checks should move you towards a more seamless integration of Deepgram's transcription capabilities with your Zoom streams.

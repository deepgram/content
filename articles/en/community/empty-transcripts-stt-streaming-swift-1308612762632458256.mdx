---
title: "Empty Transcripts in STT Streaming with Swift"
description: "Guidance on debugging empty transcripts when using Deepgram's speech-to-text API with Swift for streaming audio."
summary: "This article explains why empty transcripts may occur when utilising Deepgram's speech-to-text API for streaming audio with Swift. It covers interim results and other conditions that can trigger empty transcripts, providing actionable steps to identify and address the issue."
---

<CommunityQuestion>I'm developing a voice application with Swift and the Deepgram API, but sometimes when streaming audio, I receive empty transcripts even though there is speech. Why might this be happening and how can I troubleshoot it?</CommunityQuestion>

When utilizing speech-to-text (STT) capabilities with Swift for streaming audio, you might encounter a situation where transcripts start returning empty strings (""), even if spoken content is being transmitted. This documentation will guide you on understanding this behavior and provide actionable debugging steps to address it.

---

### Understanding Transcripts

Speech-to-text transcription involves converting audio input into text. During the streaming process, you may receive interim results which are not the final transcription but placeholders if the audio is still being processed or if there is silence. Receiving an empty transcript can be expected behavior under certain conditions, especially when:

- **Interim Results** are enabled. Interim results might return an empty string when there's silence or non-transcribing segments within your audio stream. This indicates that the engine is listening, but there's no audio to transcribe.

- **Audio Capture Issues** occur. If the audio being streamed does not have the expected speech data, or if there is an inconsistency in audio capture, the returned result may seem empty regardless of ongoing speech.

---

### Debugging Steps

#### 1. Enable Audio Dumping

Before sending audio to Deepgram, implement a method to save the audio stream to a file at the point of transmission. By examining these files, you can confirm whether the microphone is capturing audio correctly or identify sections where silence might incorrectly be recorded.

#### 2. Examine Request IDs

Leverage the request IDs provided by Deepgram for each audio transmission. These can be shared with support teams to trace and diagnose potential backend processing anomalies related to streamed audio.

#### 3. Cross-verify Configurations

Ensure interim results handling is correctly set up according to whether you want all interim results, final results only, or a combination. Verify other configuration parameters like language models, operating mode (real-time vs. pre-recorded), and endpoint addresses.

---

### Conclusion

Handling speech-to-text transcription effectively requires a clear understanding of how interim results work and diligent verification of both audio capture setup and API configuration. If you continue to face issues with empty transcripts, consider reaching out through [Deepgram's GitHub Discussions](https://github.com/orgs/deepgram/discussions) or [Discord community](https://discord.gg/deepgram) for further assistance.

---

### References

- [Deepgram Live Streaming](https://developers.deepgram.com/docs/getting-started-with-live-streaming-audio)
- [Deepgram GitHub Discussions](https://github.com/orgs/deepgram/discussions)
- [Deepgram Discord Community](https://discord.gg/deepgram)
